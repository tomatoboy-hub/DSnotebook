{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtltgqRK0cLD"
   },
   "source": [
    "## DeNA Summer Internship 2025 AIスペシャリストコース選考課題\n",
    "* DeNA Summer Internship 2025 AIスペシャリストコース選考課題のノートブック\n",
    "* PDF一枚にまとめるため、EDAとトレーニングを同じノートブックで行う\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題内容\n",
    "1. 背景\n",
    "あなたの所属する企業にて、不動産価格予測に基づくサービスの立ち上げを検討するこ\n",
    "とになりました。\n",
    "素案として、不動産の売却を検討している個人の顧客に対して、精度の高い不動産価格\n",
    "推定サービスを提供することを検討しています。\n",
    "あなたはデータサイエンスチームの一員として、モデリングの検討に参画します。\n",
    "この検討フェーズを通じて、素案の実現可能性の調査や、より良いサービスの提供に向\n",
    "けた知見の還元が期待されています。\n",
    "2. 指示\n",
    "与えられたデータを使って、予測モデルの検討レポートを作成してください。\n",
    "レポートでは、データの傾向・性質の分析、予測モデルの作成および性能評価を行い、そ\n",
    "の過程をまとめてください。\n",
    "性能評価に際しては、与えられたデータと同様の性質を持つ将来データに対してどのよ\n",
    "うな性能の予測が可能か、という観点で行ってください。\n",
    "3. 注意\n",
    "- 設定は架空のものです\n",
    "- ビジネスについては、データに登場する地域、年代を対象としていることを想定し\n",
    "てください\n",
    "- 提出するレポートはデータサイエンスチームでレビュー・検討されることを想定し、\n",
    "考察や説明を過度に平易にする必要はありません\n",
    "- 本課題の評価は予測モデルの精度に限らず、課題進行の過程やビジネスレポー\n",
    "トとしての質を考慮し、様々な観点から評価します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ\n",
    "アメリカにおける不動産情報とそれに紐付く不動産価格のデータを扱って頂きます。\n",
    "各カラムの意味は下記の通りです。\n",
    "- date: 家の売買が成立した日\n",
    "- price : 家の価格(ドル)。予測対象\n",
    "- sqft_lot: 敷地面積\n",
    "- sqft_living: 居住スペースの面積\n",
    "- grade: 家の建築・デザインを 1 から 13 で評価したもの\n",
    "- lat: 家の場所の緯度\n",
    "- long: 家の場所の経度\n",
    "- yr_built:建築された年\n",
    "- yr_renovated: 最後にリノベーションされた年"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_i949zWPT5M"
   },
   "source": [
    "### verの変更点\n",
    "- [1.0] 一通りのEDA  \n",
    "- [2.0] ベースのデータのみでトレーニング,テストまで \n",
    "    - cv: 0.18686352635400622, lb: 0.1951794332629624\n",
    "    - 大きな乖離はないため一定学習できていそう\n",
    "- [3.0] 特徴量の追加\n",
    "    - 仮説でのアイデアを一通り実装\n",
    "    - cv: 0.1909071717171483, lb: 0.19917421807093516\n",
    "    - 悪化しているため、多重共線性の問題がありそうな感じがしている\n",
    "    - trainを過学習している気配がある\n",
    "- [3.1]\n",
    "    - 'living_area_ratio', 'vacant_area',の削除\n",
    "    - cv: 0.1901787799982647, lb: 0.19904439358658832\n",
    "- [3.2]\n",
    "    - 'renov_year_diff','build_year_diff'の削除\n",
    "    - cv: 0.19056392749953852, lb: 0.19814190081273786\n",
    "- [3.3]\n",
    "    -  'is_renovated' の削除\n",
    "    - cv: 0.19056471702787575, lb: 0.19813929178130368\n",
    "- [3.4]\n",
    "    - 'date_year'の削除\n",
    "    - cv: 0.19056471702787575, lb: 0.19813929178130368\n",
    "- [3.5]\n",
    "    -  'date_month', 'date_day' の削除\n",
    "    - cv: 0.1875749876397966, lb: 0.19555628597177543\n",
    "    - \n",
    "- [3.6]\n",
    "    - 追加特徴何もなし\n",
    "    - cv: 0.18661483160191328 lb: 0.19497065058730065\n",
    "\n",
    "[やりたいこと]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3A5cD150pJ1"
   },
   "source": [
    "### 0. 環境構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6029,
     "status": "ok",
     "timestamp": 1730581863744,
     "user": {
      "displayName": "hayata shimizu",
      "userId": "02568056446308177595"
     },
     "user_tz": -540
    },
    "id": "KwjoEE3I0quP",
    "outputId": "0c51f90e-0f15-4369-ee19-1f61e07fb498"
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "from pathlib import Path\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.model_selection import TimeSeriesSplit, StratifiedGroupKFold,KFold\n",
    "from sklearn.metrics import f1_score,  confusion_matrix, mean_squared_log_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import lightgbm as lgb\n",
    "import datetime\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1730581863744,
     "user": {
      "displayName": "hayata shimizu",
      "userId": "02568056446308177595"
     },
     "user_tz": -540
    },
    "id": "Aa9iPdn6Hz0Z"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "  VER = 3.6\n",
    "  exp = 1.0\n",
    "  AUTHOR = 'SHIMIZU'\n",
    "  COMPETITION = 'DeNASummerInternship'\n",
    "\n",
    "  INPUT_DATA_PATH = Path(\"../input/\")\n",
    "  OOF_DATA_PATH = Path(\"../oof/\")\n",
    "  MODEL_DATA_PATH = Path(\"../models\")\n",
    "  OUTPUT_DATA_PATH = Path('../output')\n",
    "\n",
    "  METHOD_LIST = ['lightgbm']\n",
    "  seed = 42\n",
    "  n_folds = 5\n",
    "  target_col = \"price\"\n",
    "  metric = \"RMSLE\"\n",
    "  metric_maximize_flag = False\n",
    "  num_boost_round = 100\n",
    "  early_stopping_round = 50\n",
    "  verbose = 25\n",
    "  regression_lgb_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmsle',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.05,\n",
    "    'seed': seed,\n",
    "    'verbose':-1,\n",
    "  }\n",
    "  model_weight_dict = {'lightgbm': 1.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1730581863745,
     "user": {
      "displayName": "hayata shimizu",
      "userId": "02568056446308177595"
     },
     "user_tz": -540
    },
    "id": "cNC6sEVWLh-k"
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed: int) -> None:\n",
    "    \"\"\"乱数のseedを固定する\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1730581863745,
     "user": {
      "displayName": "hayata shimizu",
      "userId": "02568056446308177595"
     },
     "user_tz": -540
    },
    "id": "a9nOR3IpLqM2"
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# LightGBM Metric\n",
    "# ====================================================\n",
    "def lgb_rmsle(y_pred, data):\n",
    "    \"\"\"RMSLE (Root Mean Squared Logarithmic Error)を計算する関数\n",
    "\n",
    "    Args:\n",
    "        y_true (np.array): 真の値\n",
    "        y_pred (np.array): 予測値\n",
    "\n",
    "    Returns:\n",
    "        float: RMSLEスコア\n",
    "    \"\"\"\n",
    "    y_true = data.get_label()\n",
    "    y_pred = np.maximum(0, np.array(y_pred))  # 予測値を非負に制限\n",
    "\n",
    "    # sklearnの関数を使用してRMSLEを計算\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "    return 'rmsle', rmsle, CFG.metric_maximize_flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2457,
     "status": "ok",
     "timestamp": 1730581866199,
     "user": {
      "displayName": "hayata shimizu",
      "userId": "02568056446308177595"
     },
     "user_tz": -540
    },
    "id": "WoDhjn99H1qo"
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Load Dataset\n",
    "# ====================================================\n",
    "df = pd.read_csv(CFG.INPUT_DATA_PATH /\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 前提\n",
    "- **存在するデータ**\n",
    "- 不動産価格とは\n",
    "    - 不動産価格 = 広さ * デザイン * 立地 が基本要素だと思う\n",
    "    - 広さ = **敷地面積**, **居住スペース** \n",
    "    - デザイン = 中身 + 外見\n",
    "        - 中身 = **建設年**,**リノベの有無**, 部屋数, 階数, キッチン付き, トイレバス別, etc... \n",
    "        - 外見 = **デザイン**,**建設年**, 建築会社, トレンド \n",
    "    - 立地の良さ =  その家自体の立地 * 周辺環境\n",
    "        - その家自体の立地 = アメリカ * 州 * **家自体の立地**\n",
    "        - 周辺環境 = 家から周囲 n km 県内にある施設\n",
    "##### 現状の仮説\n",
    "- 予測に響きそうな要素 インパクト軸\n",
    "    - Tier1. 敷地面積, 居住スペース, 家がある州, リノベ有無\n",
    "    - Tier2. デザイン, 建築年, リノベ年\n",
    "     \n",
    "- データについて\n",
    "    - 外れ値はあるかどうか? \n",
    "        - 敷地面積については基本的に広いと思うが、東京みたいな極端に狭いやつは怪しい\n",
    "        - 飛び抜けて高い値段はあると思う ← ブランドやデザイナーズマンション的なもの\n",
    "    - 値段について\n",
    "        - 分布\n",
    "            - 正規分布よりも右に裾の長い分布になりそう\n",
    "        - 相関\n",
    "            - 予測に響きそうな要素との相関をみたい\n",
    "    - 緯度経度\n",
    "        - 分布\n",
    "            - アメリカにプロットして確認してみたい\n",
    "            - ハワイやアラスカがあるとめんどくさそう\n",
    "- 予測まわり\n",
    "    - metricについて\n",
    "        - 分布が偏っていそうなのでRMSEは適さない気がする\n",
    "        - RMSLEとかでとるのが良さそう\n",
    "    - 特徴量のアイデア **全体で1〜3時間程度を目安としてください** とのことで軽めに\n",
    "        - 外部データの利用はしない\n",
    "        - 集約特徴量は変数の選択が難しくなりそうなので最後にやるかどうか\n",
    "        - 量的変数\n",
    "            - 庭が広いのかどうか? : 居住スペース/敷地面積 or 敷地面積 - 居住スペース\n",
    "            - 築年数 : date - 建設年\n",
    "            - リノベ経過年数 : date - リノベ年\n",
    "        - 質的変数\n",
    "            - リノベ有無 : リノベ→0,1\n",
    "            - 州 : 緯度経度 → 州コード \n",
    "    - tr,val,testのsplit\n",
    "        - 8:2のさらに8:2で分ける感じがいいかな\n",
    "        - どこをtestデータにするか?　売買成立日で並べてtimeseriesにした方が良さげか?\n",
    "        - 同じ家が含まれないようにしたいけど家IDがないから、上である程度対処できることを期待"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1730581866200,
     "user": {
      "displayName": "hayata shimizu",
      "userId": "02568056446308177595"
     },
     "user_tz": -540
    },
    "id": "kBzvnKSINhTS",
    "outputId": "def99d5c-92fb-44ef-b5c5-56677f2d80ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21613, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>grade</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20141013</td>\n",
       "      <td>221900</td>\n",
       "      <td>5650</td>\n",
       "      <td>1180</td>\n",
       "      <td>7</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20141209</td>\n",
       "      <td>538000</td>\n",
       "      <td>7242</td>\n",
       "      <td>2570</td>\n",
       "      <td>7</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20150225</td>\n",
       "      <td>180000</td>\n",
       "      <td>10000</td>\n",
       "      <td>770</td>\n",
       "      <td>6</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20141209</td>\n",
       "      <td>604000</td>\n",
       "      <td>5000</td>\n",
       "      <td>1960</td>\n",
       "      <td>7</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20150218</td>\n",
       "      <td>510000</td>\n",
       "      <td>8080</td>\n",
       "      <td>1680</td>\n",
       "      <td>8</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date   price  sqft_lot  sqft_living  grade      lat     long  yr_built  \\\n",
       "0  20141013  221900      5650         1180      7  47.5112 -122.257      1955   \n",
       "1  20141209  538000      7242         2570      7  47.7210 -122.319      1951   \n",
       "2  20150225  180000     10000          770      6  47.7379 -122.233      1933   \n",
       "3  20141209  604000      5000         1960      7  47.5208 -122.393      1965   \n",
       "4  20150218  510000      8080         1680      8  47.6168 -122.045      1987   \n",
       "\n",
       "   yr_renovated  \n",
       "0             0  \n",
       "1          1991  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>grade</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>20140521</td>\n",
       "      <td>360000</td>\n",
       "      <td>1131</td>\n",
       "      <td>1530</td>\n",
       "      <td>8</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>20150223</td>\n",
       "      <td>400000</td>\n",
       "      <td>5813</td>\n",
       "      <td>2310</td>\n",
       "      <td>8</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>20140623</td>\n",
       "      <td>402101</td>\n",
       "      <td>1350</td>\n",
       "      <td>1020</td>\n",
       "      <td>7</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>20150116</td>\n",
       "      <td>400000</td>\n",
       "      <td>2388</td>\n",
       "      <td>1600</td>\n",
       "      <td>8</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>20141015</td>\n",
       "      <td>325000</td>\n",
       "      <td>1076</td>\n",
       "      <td>1020</td>\n",
       "      <td>7</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   price  sqft_lot  sqft_living  grade      lat     long  \\\n",
       "21608  20140521  360000      1131         1530      8  47.6993 -122.346   \n",
       "21609  20150223  400000      5813         2310      8  47.5107 -122.362   \n",
       "21610  20140623  402101      1350         1020      7  47.5944 -122.299   \n",
       "21611  20150116  400000      2388         1600      8  47.5345 -122.069   \n",
       "21612  20141015  325000      1076         1020      7  47.5941 -122.299   \n",
       "\n",
       "       yr_built  yr_renovated  \n",
       "21608      2009             0  \n",
       "21609      2014             0  \n",
       "21610      2009             0  \n",
       "21611      2004             0  \n",
       "21612      2008             0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------欠損値の割合(%)------\n",
      "date            0.0\n",
      "price           0.0\n",
      "sqft_lot        0.0\n",
      "sqft_living     0.0\n",
      "grade           0.0\n",
      "lat             0.0\n",
      "long            0.0\n",
      "yr_built        0.0\n",
      "yr_renovated    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 欠損の確認 → 欠損なし dtypeもfloat\n",
    "print(df.shape)\n",
    "display(df.head())\n",
    "display(df.tail())\n",
    "print(\"------欠損値の割合(%)------\")\n",
    "print(df.isna().sum() / len(df) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各変数の分布を可視化\n",
    "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f'{col}の分布')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    if col == CFG.target_col:\n",
    "        continue\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.scatterplot(x=df[col], y=df[CFG.target_col])\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(CFG.target_col)\n",
    "    plt.title(f'Scatter plot: {col} vs {CFG.target_col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相関係数行列の可視化\n",
    "corr_matrix = df.corr(numeric_only=True)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('相関係数行列')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 仮説に対して\n",
    "- 予測に響きそうな要素 インパクト軸\n",
    "    - Tier1. 敷地面積, 居住スペース, 家がある州, リノベ有無  \n",
    "    → 敷地面積の相関が低い だだっ広いだけのスペースがありそう、重要なのは居住スペース\n",
    "\n",
    "    - Tier2. デザイン, 建築年, リノベ年\n",
    "- データについて\n",
    "    - 外れ値はあるかどうか? \n",
    "        - 敷地面積については基本的に広いと思うが、東京みたいな極端に狭いやつは怪しい\n",
    "        - 飛び抜けて高い値段はあると思う ← ブランドやデザイナーズマンション的なもの  \n",
    "        →敷地面積はmaxの方は外れ値があるが、minの方は大丈夫そう  \n",
    "        →値段も同様\n",
    "    - 値段について\n",
    "        - 分布\n",
    "            - 正規分布よりも右に裾の長い分布になりそう  \n",
    "            →ぱっと見変換ミスとかはなさそうな感じ\n",
    "        - 相関\n",
    "            - 値段と他の相関をみたい\n",
    "    - 緯度経度\n",
    "        - 分布\n",
    "            - アメリカにプロットして確認してみたい\n",
    "            - ハワイやアラスカがあるとめんどくさそう  \n",
    "            →緯度経度の範囲的に本大陸の中だけっぽい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'].astype(int).astype(str), format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainとtestデータの分割\n",
    "df.sort_values(by='date', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "train_df = df.iloc[:int(len(df)*0.8)]\n",
    "test_df = df.iloc[int(len(df)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TC9imwKMsMB",
    "outputId": "8f84d1b1-a243-44b3-c30e-59a00f6b1df7"
   },
   "outputs": [],
   "source": [
    "def Preprocessing(train_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"データの前処理を行う\"\"\"\n",
    "    train_df = train_df.copy()\n",
    "    def process_date_col(input_df):\n",
    "        output_df = input_df.copy()\n",
    "        date_columns = [col for col in output_df.columns if 'date' in col]\n",
    "        for col in date_columns:\n",
    "            output_df[col + '_year'] = output_df[col].dt.year\n",
    "            output_df[col + '_month'] = output_df[col].dt.month\n",
    "            output_df[col + '_day'] = output_df[col].dt.day\n",
    "        output_df = output_df.drop(columns=date_columns)\n",
    "        return output_df\n",
    "    \n",
    "    def living_area_ratio(input_df):\n",
    "        output_df = input_df.copy()\n",
    "        output_df['living_area_ratio'] = output_df['sqft_living'] / output_df['sqft_lot']\n",
    "        return output_df\n",
    "    \n",
    "    def vacant_area(input_df):\n",
    "        output_df = input_df.copy()\n",
    "        output_df['vacant_area'] = output_df['sqft_lot'] - output_df['sqft_living']\n",
    "        return output_df\n",
    "    \n",
    "    def is_renovated(input_df):\n",
    "        output_df = input_df.copy()\n",
    "        output_df['is_renovated'] = output_df['yr_renovated'].notna()\n",
    "        return output_df\n",
    "    \n",
    "    def process_renov_year(input_df):\n",
    "        output_df = input_df.copy()\n",
    "        # 0をNaNに置き換える（データによっては空文字 '' なども対象にする）\n",
    "        output_df['yr_renovated'] = output_df['yr_renovated'].replace(0, np.nan)\n",
    "        return output_df\n",
    "    \n",
    "    def renov_year_diff(input_df):\n",
    "        output_df = input_df.copy()\n",
    "        # 0よりもnan扱いの方が良いのでは? \n",
    "        output_df['renov_year_diff'] = output_df['yr_renovated'] - output_df['yr_built']\n",
    "        return output_df\n",
    "    \n",
    "    def built_year_diff(input_df):\n",
    "        output_df = input_df.copy()\n",
    "        output_df['build_year_diff'] =  output_df['date_year'] - output_df['yr_built']\n",
    "        return output_df\n",
    "    \n",
    "    \n",
    "\n",
    "    # train_df = process_date_col(train_df)\n",
    "    train_df = living_area_ratio(train_df)\n",
    "    # train_df = vacant_area(train_df)\n",
    "    # train_df = is_renovated(train_df)\n",
    "    # train_df = process_renov_year(train_df)\n",
    "    # train_df = renov_year_diff(train_df)\n",
    "    # train_df = built_year_diff(train_df)\n",
    "    return train_df\n",
    "\n",
    "train = Preprocessing(train_df)\n",
    "test = Preprocessing(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "omk5T97IRffs"
   },
   "outputs": [],
   "source": [
    "categorical_features = ['grade']\n",
    "numerical_features = ['sqft_lot', 'sqft_living','lat', 'long','yr_built', 'yr_renovated']\n",
    "#'living_area_ratio', 'vacant_area',\n",
    "#'renov_year_diff','build_year_diff'\n",
    "# 'is_renovated'\n",
    "# 'date_year'\n",
    "# 'date_month', 'date_day'\n",
    "features = categorical_features + numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730556586095,
     "user": {
      "displayName": "hayata shimizu",
      "userId": "02568056446308177595"
     },
     "user_tz": -540
    },
    "id": "O3ldEK2TUx5J",
    "outputId": "b593f771-ee58-41f2-af74-452276b23a52"
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Encoding features\n",
    "# ========================================\n",
    "le_dict = {}\n",
    "for categorical_feature in tqdm(categorical_features):\n",
    "    le = LabelEncoder()\n",
    "    # Fit on the combined unique values from both train and test\n",
    "    all_values = list(train[categorical_feature].unique()) + list(test[categorical_feature].unique())\n",
    "    le.fit(all_values)\n",
    "\n",
    "    # Transform train and test\n",
    "    train[categorical_feature] = le.transform(train[categorical_feature])\n",
    "    test[categorical_feature] = le.transform(test[categorical_feature])\n",
    "    le_dict[categorical_feature] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8b6blRtElECb"
   },
   "outputs": [],
   "source": [
    "def add_aggrigation_feats(train, test, num_cols, cat_cols, agg_cols=['min', 'max', 'mean', 'std']):\n",
    "  for col in cat_cols:\n",
    "      grp_df = train.groupby(col)[num_cols].agg(agg_cols)\n",
    "      grp_df.columns = [f'{col}_' + '_'.join(c) for c in grp_df.columns]\n",
    "      train = train.merge(grp_df, on=col, how='left')\n",
    "      test = test.merge(grp_df, on=col, how='left')\n",
    "\n",
    "  return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "aErKqiVNVGY3"
   },
   "outputs": [],
   "source": [
    "def lightgbm_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    \"\"\"LightGBMの学習を行う\"\"\"\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=categorical_features)\n",
    "    lgb_valid = lgb.Dataset(x_valid, y_valid, categorical_feature=categorical_features)\n",
    "    model = lgb.train(\n",
    "                params = CFG.regression_lgb_params,\n",
    "                train_set = lgb_train,\n",
    "                num_boost_round = 500,\n",
    "                valid_sets = [lgb_train, lgb_valid],\n",
    "                feval = lgb_rmsle,\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=50,\n",
    "                                              verbose=-1)]\n",
    "            )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def gradient_boosting_model_cv_training(method: str, train_df: pd.DataFrame, features: list, categorical_features: list):\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    oof_predictions = np.zeros(len(train_df))\n",
    "    oof_fold = np.zeros(len(train_df))\n",
    "    tss = TimeSeriesSplit(n_splits=CFG.n_folds)\n",
    "    y_true_original = train_df[CFG.target_col].values \n",
    "    all_valid_indices = []\n",
    "    #sgkf = StratifiedGroupKFold(n_splits=CFG.n_folds)\n",
    "    #kf = KFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
    "    #for fold, (train_index, valid_index) in enumerate(tss.split(train_df)):\n",
    "    for fold, (train_index, valid_index) in enumerate(tss.split(train_df[features], train_df[CFG.target_col])):\n",
    "        print('-'*50)\n",
    "        print(f'{method} training fold {fold+1}')\n",
    "\n",
    "        x_train = train_df[features].iloc[train_index]\n",
    "        x_valid = train_df[features].iloc[valid_index]\n",
    "        y_train = train_df[CFG.target_col].iloc[train_index]\n",
    "        y_valid = train_df[CFG.target_col].iloc[valid_index]\n",
    "        if method == 'lightgbm':\n",
    "           model, valid_pred_log = lightgbm_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "\n",
    "        # Save best model\n",
    "        pickle.dump(model, open(CFG.MODEL_DATA_PATH / f'{method}_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'wb'))\n",
    "        # Add to out of folds array\n",
    "        oof_predictions[valid_index] = valid_pred_log\n",
    "        all_valid_indices.extend(valid_index)\n",
    "        oof_fold[valid_index] = fold + 1\n",
    "        del x_train, x_valid, y_train, y_valid, model, valid_pred_log\n",
    "        gc.collect()\n",
    "\n",
    "    # Compute out of folds metric\n",
    "    score = np.sqrt(mean_squared_log_error(y_true_original[all_valid_indices], oof_predictions[all_valid_indices]))\n",
    "    \n",
    "    print(f'{method} out of folds CV RMSLE score is {score}')\n",
    "    \n",
    "    oof_df = pd.DataFrame({CFG.target_col: train_df[CFG.target_col], f'{method}_prediction': oof_predictions, 'fold': oof_fold})\n",
    "    oof_df.to_csv(CFG.OOF_DATA_PATH / f'oof_{method}_seed{CFG.seed}_{CFG.AUTHOR}_ver{CFG.VER}.csv', index = False)\n",
    "\n",
    "def Learning(train_feats):\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        print(method)\n",
    "        gradient_boosting_model_cv_training(method, train, train_feats, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'price', 'sqft_lot', 'sqft_living', 'grade', 'lat', 'long',\n",
       "       'yr_built', 'yr_renovated', 'living_area_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grade', 'sqft_lot', 'sqft_living', 'lat', 'long', 'yr_built', 'yr_renovated']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 82349,
     "status": "ok",
     "timestamp": 1730556678058,
     "user": {
      "displayName": "hayata shimizu",
      "userId": "02568056446308177595"
     },
     "user_tz": -540
    },
    "id": "Aat7UYjJW9Sa",
    "outputId": "1f6aaee7-e913-4833-81ee-5303ee0ec439"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[190]\ttraining's rmsle: 0.137628\tvalid_1's rmsle: 0.191134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kslab/shimizu/.conda/envs/recsys/lib/python3.11/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/home/kslab/shimizu/.conda/envs/recsys/lib/python3.11/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/home/kslab/shimizu/.conda/envs/recsys/lib/python3.11/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "lightgbm training fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kslab/shimizu/.conda/envs/recsys/lib/python3.11/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/home/kslab/shimizu/.conda/envs/recsys/lib/python3.11/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/home/kslab/shimizu/.conda/envs/recsys/lib/python3.11/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[273]\ttraining's rmsle: 0.138188\tvalid_1's rmsle: 0.181118\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kslab/shimizu/.conda/envs/recsys/lib/python3.11/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/home/kslab/shimizu/.conda/envs/recsys/lib/python3.11/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/home/kslab/shimizu/.conda/envs/recsys/lib/python3.11/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[307]\ttraining's rmsle: 0.141935\tvalid_1's rmsle: 0.186052\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kslab/shimizu/.conda/envs/recsys/lib/python3.11/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/home/kslab/shimizu/.conda/envs/recsys/lib/python3.11/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/home/kslab/shimizu/.conda/envs/recsys/lib/python3.11/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's rmsle: 0.134214\tvalid_1's rmsle: 0.179344\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 5\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kslab/shimizu/.conda/envs/recsys/lib/python3.11/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/home/kslab/shimizu/.conda/envs/recsys/lib/python3.11/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/home/kslab/shimizu/.conda/envs/recsys/lib/python3.11/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's rmsle: 0.138113\tvalid_1's rmsle: 0.194961\n",
      "lightgbm out of folds CV RMSLE score is 0.18661483160191328\n"
     ]
    }
   ],
   "source": [
    "Learning(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "xOMr3U_jhvaA"
   },
   "outputs": [],
   "source": [
    "def lightgbm_inference(x_test: pd.DataFrame):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(open(CFG.MODEL_DATA_PATH / f'lightgbm_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "def gradient_boosting_model_inference(method: str, test_df: pd.DataFrame, features: list, categorical_features: list):\n",
    "    x_test = test_df[features]\n",
    "    if method == 'lightgbm':\n",
    "        test_pred = lightgbm_inference(x_test)\n",
    "    return test_pred\n",
    "def Predicting(input_df: pd.DataFrame, features: list, categorical_features: list):\n",
    "    output_df = input_df.copy()\n",
    "    output_df['pred_prob'] = 0\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        output_df[f'{method}_pred_prob'] = gradient_boosting_model_inference(method, input_df, features, categorical_features)\n",
    "        output_df['pred_prob'] += CFG.model_weight_dict[method] * output_df[f'{method}_pred_prob']\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "QiVvTJ_yiZVm"
   },
   "outputs": [],
   "source": [
    "test_df = Predicting(test, features, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>grade</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>living_area_ratio</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>lightgbm_pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17290</th>\n",
       "      <td>2015-03-10</td>\n",
       "      <td>762450</td>\n",
       "      <td>8640</td>\n",
       "      <td>2570</td>\n",
       "      <td>8</td>\n",
       "      <td>47.5956</td>\n",
       "      <td>-122.172</td>\n",
       "      <td>1958</td>\n",
       "      <td>0</td>\n",
       "      <td>0.297454</td>\n",
       "      <td>699278.485796</td>\n",
       "      <td>699278.485796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17291</th>\n",
       "      <td>2015-03-10</td>\n",
       "      <td>390000</td>\n",
       "      <td>6991</td>\n",
       "      <td>1640</td>\n",
       "      <td>7</td>\n",
       "      <td>47.7255</td>\n",
       "      <td>-122.327</td>\n",
       "      <td>1967</td>\n",
       "      <td>0</td>\n",
       "      <td>0.234587</td>\n",
       "      <td>392376.333447</td>\n",
       "      <td>392376.333447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17292</th>\n",
       "      <td>2015-03-10</td>\n",
       "      <td>339000</td>\n",
       "      <td>8459</td>\n",
       "      <td>2350</td>\n",
       "      <td>9</td>\n",
       "      <td>47.3043</td>\n",
       "      <td>-122.349</td>\n",
       "      <td>1989</td>\n",
       "      <td>0</td>\n",
       "      <td>0.277811</td>\n",
       "      <td>362200.508622</td>\n",
       "      <td>362200.508622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17293</th>\n",
       "      <td>2015-03-10</td>\n",
       "      <td>194000</td>\n",
       "      <td>7700</td>\n",
       "      <td>1760</td>\n",
       "      <td>7</td>\n",
       "      <td>47.3299</td>\n",
       "      <td>-122.318</td>\n",
       "      <td>1962</td>\n",
       "      <td>0</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>238000.387464</td>\n",
       "      <td>238000.387464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17294</th>\n",
       "      <td>2015-03-10</td>\n",
       "      <td>641500</td>\n",
       "      <td>9084</td>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>47.5007</td>\n",
       "      <td>-122.382</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>0.110084</td>\n",
       "      <td>353742.676533</td>\n",
       "      <td>353742.676533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date   price  sqft_lot  sqft_living  grade      lat     long  \\\n",
       "17290 2015-03-10  762450      8640         2570      8  47.5956 -122.172   \n",
       "17291 2015-03-10  390000      6991         1640      7  47.7255 -122.327   \n",
       "17292 2015-03-10  339000      8459         2350      9  47.3043 -122.349   \n",
       "17293 2015-03-10  194000      7700         1760      7  47.3299 -122.318   \n",
       "17294 2015-03-10  641500      9084         1000      7  47.5007 -122.382   \n",
       "\n",
       "       yr_built  yr_renovated  living_area_ratio      pred_prob  \\\n",
       "17290      1958             0           0.297454  699278.485796   \n",
       "17291      1967             0           0.234587  392376.333447   \n",
       "17292      1989             0           0.277811  362200.508622   \n",
       "17293      1962             0           0.228571  238000.387464   \n",
       "17294      1950             0           0.110084  353742.676533   \n",
       "\n",
       "       lightgbm_pred_prob  \n",
       "17290       699278.485796  \n",
       "17291       392376.333447  \n",
       "17292       362200.508622  \n",
       "17293       238000.387464  \n",
       "17294       353742.676533  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.19497065058730065\n"
     ]
    }
   ],
   "source": [
    "score = np.sqrt(mean_squared_log_error(test_df[CFG.target_col],test_df[\"pred_prob\"]))\n",
    "print(f\"RMSLE: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "Zv5UaZJTi75Q"
   },
   "outputs": [],
   "source": [
    "sample_submit = pd.read_csv(CFG.SUB_FILE_PATH, index_col=0, header=None) # 応募用サンプルファイル\n",
    "sample_submit[1] = test_df[[\"pred_prob\"]].values\n",
    "sample_submit.to_csv(CFG.SUB_DATA_PATH / f'exp{CFG.exp}_seed{CFG.seed}_ver{CFG.VER}_{CFG.AUTHOR}_submission.csv', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "executionInfo": {
     "elapsed": 605,
     "status": "ok",
     "timestamp": 1730534335314,
     "user": {
      "displayName": "hayata shimizu",
      "userId": "02568056446308177595"
     },
     "user_tz": -540
    },
    "id": "jRIUD6aFe6Za",
    "outputId": "936fc2a0-d1d0-4577-fb68-88205a7c0c27"
   },
   "outputs": [],
   "source": [
    "model = pickle.load(open(CFG.MODEL_DATA_PATH / f'lightgbm_fold1_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "importance_df = pd.DataFrame(model.feature_importance(), index=model.feature_name(), columns=['importance'])\n",
    "importance_df['importance'] = importance_df['importance'] / np.sum(importance_df['importance'])\n",
    "importance_df.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
